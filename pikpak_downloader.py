#!/usr/bin/env python3
import os
import sys
import json
import time
import requests
from pathlib import Path
from typing import Dict, List, Optional
from urllib.parse import urlparse, parse_qs
from dotenv import load_dotenv
from tqdm import tqdm
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed

class PikPakDownloader:
    BASE_URL = "https://api-drive.mypikpak.com/v1"
    SHARE_BASE_URL = "https://api-drive.mypikpak.com/v1"
    
    def __init__(self, max_workers: int = 3):
        self.session = requests.Session()
        self.max_workers = max_workers
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
    
    def get_share_info(self, share_url: str) -> Dict:
        """è·å–åˆ†äº«é“¾æ¥ä¿¡æ¯"""
        parsed_url = urlparse(share_url)
        # /s/<share_id>/<file_id>
        path_parts = parsed_url.path.strip('/').split('/')
        if len(path_parts) < 3 or path_parts[0] != 's':
            raise ValueError("åˆ†äº«é“¾æ¥æ ¼å¼ä¸æ­£ç¡®")
        share_id = path_parts[1]
        file_id = path_parts[2]
        
        url = f"{self.SHARE_BASE_URL}/share/{share_id}"
        
        # æ·»åŠ é‡è¯•æœºåˆ¶
        for attempt in range(3):
            try:
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                info = response.json()
                info['share_id'] = share_id
                info['file_id'] = file_id
                return info
            except requests.exceptions.RequestException as e:
                if attempt == 2:
                    raise e
                print(f"è·å–åˆ†äº«ä¿¡æ¯å¤±è´¥ï¼Œé‡è¯•ä¸­... ({attempt + 1}/3)")
                time.sleep(2)
    
    def get_share_files(self, share_id: str, parent_id: str = "root") -> List[Dict]:
        """è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨ï¼Œæ”¯æŒåˆ†é¡µ"""
        url = f"{self.SHARE_BASE_URL}/share/{share_id}/files"
        params = {
            "parent_id": parent_id,
            "page_token": "",
            "page_size": 100,
            "with_audit": "true",
            "thumbnail_size": "SIZE_MEDIUM"
        }
        
        files = []
        page_count = 0
        
        while True:
            try:
                response = self.session.get(url, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                current_files = data.get("files", [])
                files.extend(current_files)
                page_count += 1
                
                print(f"å·²è·å–ç¬¬ {page_count} é¡µï¼Œå…± {len(current_files)} ä¸ªæ–‡ä»¶")
                
                if not data.get("next_page_token"):
                    break
                params["page_token"] = data["next_page_token"]
                
            except requests.exceptions.RequestException as e:
                print(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
                break
                
        return files
    
    def get_download_url(self, share_id: str, file_id: str) -> str:
        """è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥"""
        url = f"{self.SHARE_BASE_URL}/share/{share_id}/download"
        params = {"file_id": file_id}
        
        for attempt in range(3):
            try:
                response = self.session.get(url, params=params, timeout=30)
                response.raise_for_status()
                return response.json()["download_url"]
            except requests.exceptions.RequestException as e:
                if attempt == 2:
                    raise e
                print(f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥ï¼Œé‡è¯•ä¸­... ({attempt + 1}/3)")
                time.sleep(1)
    
    def download_file(self, url: str, filepath: Path, chunk_size: int = 8192) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            filepath.parent.mkdir(parents=True, exist_ok=True)
            
            # è·å–æ–‡ä»¶å¤§å°
            response = self.session.head(url, timeout=30)
            total_size = int(response.headers.get("content-length", 0))
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶
            initial_pos = filepath.stat().st_size if filepath.exists() else 0
            
            if initial_pos >= total_size and total_size > 0:
                print(f"æ–‡ä»¶ {filepath.name} å·²å®Œæ•´ä¸‹è½½")
                return True
            
            # è®¾ç½®æ–­ç‚¹ç»­ä¼ å¤´
            headers = {"Range": f"bytes={initial_pos}-"} if initial_pos > 0 else {}
            
            with self.session.get(url, headers=headers, stream=True, timeout=30) as response:
                response.raise_for_status()
                
                # åˆ›å»ºè¿›åº¦æ¡
                progress = tqdm(
                    total=total_size,
                    initial=initial_pos,
                    unit="iB",
                    unit_scale=True,
                    desc=filepath.name[:50]  # é™åˆ¶æ–‡ä»¶åé•¿åº¦
                )
                
                mode = "ab" if initial_pos > 0 else "wb"
                with open(filepath, mode) as f:
                    for chunk in response.iter_content(chunk_size=chunk_size):
                        if chunk:
                            size = f.write(chunk)
                            progress.update(size)
                
                progress.close()
                print(f"âœ“ ä¸‹è½½å®Œæˆ: {filepath.name}")
                return True
                
        except Exception as e:
            print(f"âœ— ä¸‹è½½å¤±è´¥ {filepath.name}: {e}")
            return False
    
    def download_folder_recursive(self, share_id: str, folder_id: str, output_path: Path) -> None:
        """é€’å½’ä¸‹è½½æ–‡ä»¶å¤¹å†…å®¹"""
        files = self.get_share_files(share_id, parent_id=folder_id)
        
        if not files:
            print(f"æ–‡ä»¶å¤¹ä¸ºç©º: {output_path}")
            return
        
        # åˆ†ç¦»æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        file_items = []
        folder_items = []
        
        for item in files:
            if item["kind"] == "drive#file":
                file_items.append(item)
            elif item["kind"] == "drive#folder":
                folder_items.append(item)
        
        print(f"å‘ç° {len(file_items)} ä¸ªæ–‡ä»¶ï¼Œ{len(folder_items)} ä¸ªæ–‡ä»¶å¤¹")
        
        # ä¸‹è½½æ–‡ä»¶
        if file_items:
            self.download_files_batch(share_id, file_items, output_path)
        
        # é€’å½’ä¸‹è½½å­æ–‡ä»¶å¤¹
        for folder in folder_items:
            folder_path = output_path / folder["name"]
            folder_path.mkdir(parents=True, exist_ok=True)
            print(f"\nè¿›å…¥æ–‡ä»¶å¤¹: {folder['name']}")
            self.download_folder_recursive(share_id, folder["id"], folder_path)
    
    def download_files_batch(self, share_id: str, files: List[Dict], output_path: Path) -> None:
        """æ‰¹é‡ä¸‹è½½æ–‡ä»¶"""
        def download_single_file(file_info):
            try:
                file_path = output_path / file_info["name"]
                download_url = self.get_download_url(share_id, file_info["id"])
                success = self.download_file(download_url, file_path)
                return success, file_info["name"]
            except Exception as e:
                print(f"ä¸‹è½½æ–‡ä»¶ {file_info['name']} æ—¶å‡ºé”™: {e}")
                return False, file_info["name"]
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘ä¸‹è½½
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_file = {executor.submit(download_single_file, file): file for file in files}
            
            success_count = 0
            total_count = len(files)
            
            for future in as_completed(future_to_file):
                success, filename = future.result()
                if success:
                    success_count += 1
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.5)
        
        print(f"\næ‰¹é‡ä¸‹è½½å®Œæˆ: {success_count}/{total_count} ä¸ªæ–‡ä»¶æˆåŠŸä¸‹è½½")
    
    def process_share(self, share_url: str, output_dir: str = "/Download") -> None:
        """å¤„ç†åˆ†äº«é“¾æ¥ï¼Œä¸‹è½½æ‰€æœ‰å†…å®¹"""
        try:
            print(f"æ­£åœ¨è§£æåˆ†äº«é“¾æ¥: {share_url}")
            share_info = self.get_share_info(share_url)
            
            share_id = share_info["share_id"]
            share_name = share_info.get("share_name", "PikPak_Download")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_path = Path(output_dir) / share_name
            output_path.mkdir(parents=True, exist_ok=True)
            
            print(f"ä¸‹è½½ç›®å½•: {output_path}")
            print(f"åˆ†äº«åç§°: {share_name}")
            
            # å¼€å§‹é€’å½’ä¸‹è½½
            self.download_folder_recursive(share_id, share_info["file_id"], output_path)
            
            print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å·²ä¸‹è½½åˆ°: {output_path}")
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
            print("æç¤º: å¯èƒ½éœ€è¦æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            sys.exit(1)

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python pikpak_downloader.py <åˆ†äº«é“¾æ¥> [ä¸‹è½½ç›®å½•]")
        print("ç¤ºä¾‹: python pikpak_downloader.py https://mypikpak.com/s/xxx/xxx")
        print("ç¤ºä¾‹: python pikpak_downloader.py https://mypikpak.com/s/xxx/xxx /Users/username/Downloads")
        sys.exit(1)
    
    share_url = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "/Download"
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹ï¼Œå¯ä»¥è°ƒæ•´å¹¶å‘æ•°
    downloader = PikPakDownloader(max_workers=2)  # é™ä½å¹¶å‘æ•°é¿å…è¢«é™åˆ¶
    
    print("=== PikPak æ‰¹é‡ä¸‹è½½å™¨ ===")
    print(f"åˆ†äº«é“¾æ¥: {share_url}")
    print(f"ä¸‹è½½ç›®å½•: {output_dir}")
    print("å¼€å§‹ä¸‹è½½...\n")
    
    downloader.process_share(share_url, output_dir)

if __name__ == "__main__":
    main()